\chapter{Validation and Conclusions}
\section{Performance of SpLATS}
  \subsection{Feature Matrix}
    \begin{tabular}{p{0.3\textwidth} | p{0.5\textwidth}}
    Aim & Success \\
    \hline
    Compare two versions of code &
    We can generate tests, which can be easily adapted to be run against another version of the code.
    It is also possible to generate tests based on one version of a piece of code, and then run those tests on another version of the same code, marking the deltas. \\
    Set configuration options & The user interfaces can be used to control how the search space is traversed, as well as the input and output options \\
    Inspect code coverage of tests & By default, code coverage of generated tests will be output along with the results of the tests. \\
    Reproduce tests & Tests are reproducible, given the same input SpLATS will behave in a deterministic way. For the random traversal a seed is provided as input, so although SpLATS will behave
    in a pseudorandom way, the tests will be recreatable if the same seed is given.\\
    Have a CLI &
    A simple wrapper for SpLATS was implemented \\
    \hline
    \end{tabular}

    \begin{tabular}{p{0.3\textwidth} | p{0.5\textwidth}}
    Aim & Success \\
    \hline
    Have a GUI &
    This works, and is especially useful for manual traversal \\
    Test basic program semantics &
    It does this to a very basic level implicitly, but it's not investigated much \\
    Test code across multiple computers at once &
    As SpLATS has a CLI suitable for writing scripts around, it is possible to run multiple instances across a distributed system, such as Condor; however, the tool doesn't distribute a single instance. \\
    \hline
    Have a website &
    While it would have been useful for any future users it was deemed more important to improve the tool itself. It would be relatively simple to create some online documentation using a tool such as 
    RDoc\footnote{\url{http://rdoc.sourceforge.net/}} or YARD\footnote{\url{http://yardoc.org/}} \\
    Have different traversal mechaisms &
    There are 3 traversal mechanisms: depth-first, random and manual. \\
    \end{tabular}

  \subsection{Evaluation of Quality of Generated Tests}
    Several sample CUTs are used to evaluate and test the quality of SpLATS'
test generation. We will also compare the ability of the depth-limited search to
reach full coverage to the random traversal strategy.

    The test classes used were:
    \begin{itemize}
      \item Addition - 1 plus the argument, used to test Ruby's arithmetic
internals
      \item SimpleTest - Tests arbitrary methods called upon arguments to the
function, branches based upon the result of the method call
      \item LinkedList - A standard LinkedList implementation, uses both
iterative and recursive algorithms
      \item QuickSort - A recursive quick sort implementation
      \item ISBN-Tools - An open-source library to check the validity of ISBN
numbers, makes heavy use of regular expressions and string methods
    \end{itemize}

  \subsubsection{Result}

    \begin{tabular}{l|cccc}
CUT & Search Depth (Mock Depth) & Generation Time/m:s & Tests & Coverage \\
\hline
Addition & 2 & 0.051 & 6 & 3/3 (100\%) \\
\hline
SimpleTest & 2 & 0.064 & 32 & 12/12 (100\%) \\
\hline
LinkedList & 2 & 0.056 & 31 & 35/47 (74\%) \\
& 3 & 0.147 & 306 & 45/47 (96\%) \\
& 4 & 2.118 & 3859 & 46/47 (98\%)\\
\hline
QuickSort & 2 (3) & 5:57.2 & 351927 & Not testable\\
& 2 (2) & 3.356 & 4272 & 8/8 (100\%) \\
& 2 (1) & 0.344 & 87 & 8/8 (100\%) \\
\hline
ISBN-Tools & 2 (1) & 0.056 & 13 & 10/16 (63\%) \\
& 2 (2) & 0.072 & 57 & 10/16 (63\%) \\
& 2 (3) & & & \\
\end{tabular}

\subsubsection{Analysis}
  The more successful test cases in the sample set were the ones which did not create large chains of calls on Mock objects.

  \subsection{Test Generation and Comparison}
    \subsubsection{Analysis}
    \subsubsection{Design}
    \subsubsection{Implementation}
    \subsubsection{Testing}
  \subsection{Code Coverage}
  \subsection{ZenTest}
  \subsection{Testing by Inspection}
  - Code coverage showed Tom that it wasn't doing 1 + 1 coerce error.
